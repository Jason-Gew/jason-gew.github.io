<!DOCTYPE html>
<html lang="en,zh-cn">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Jason Ge Wu">



    <meta name="description" content="Jason's Personal Blog. Tech, Travel and Life.">


    <meta name="keywords" content="Jason Ge Wu,Jason-Gew,Big Data,Distributed System,Risk Management,Technology,Travel">


<title>Hadoop MapReduce (分布式计算框架) | Jason Ge Wu</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    
    <script src="/js/easyXDM.min.js"></script>
    
    <script src="/js/busuanzi.pure.js"></script>
    



    
    
        
    


<meta name="generator" content="Hexo 5.2.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo">
                <a href="/" style="font-weight: bold">Jason&#39;s Blog</a>
            </div>
            <div class="menu navbar-right" style="font-weight: bold">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/message">Msgs</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Jason&#39;s Blog</a>
                    <a id="mobile-toggle-theme">&nbsp;·&nbsp;Dark</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/message">Msgs</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if (toggleMenu.classList.contains("active")) {
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        } else {
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <br/>
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand All</a>
        <a onclick="go_top()">Go Top</a>
        <a onclick="go_bottom()">Go Bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse All"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand All"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Hadoop MapReduce (分布式计算框架)</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" >Jason Ge Wu</a>
                    
                    <br />
                    
                        <span class="post-time">
                        Date: <a href="#">2021-11-30&nbsp;
                                &nbsp;08:18:28</a>
                        </span>
                    
                    <br />
                    
                        <span class="post-category">
                        Category:
                            
                                <a href="/categories/Tech/">Tech</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <div style="text-align: center">
    <p style="color: OrangeRed; font-weight: bold">本文基于Hadoop 3.X</p>
</div>

<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Hadoop <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">MapReduce</a> 最初理论源于 Google 2004年论文&lt;MapReduce: Simplified Data Processing on Large Clusters&gt; <a target="_blank" rel="noopener" href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf" title="MapReduce: Simplified Data Processing on Large Clusters">^1</a>， 是一个分布式计算程序框架，具备一定的可靠性与容错性。常用于处理大数据并行计算分析。MapReduce 框架包含两个重要的任务类型，即 Map 和 Reduce。</p>
<p>计算作业将输入数据集拆分为独立的文件块，这些文件块由 Map 任务以并行的方式处理，其中单个元素被分解为键-值对。随后MR框架对映射的输出进行排序，再将数据再输入给 Reduce 任务。作业的输入和输出一般都存储在文件系统 (HDFS) 中。</p>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p>MapReduce 系统包含一个主资源管理器 (ResourceManager)，每个节点的 NodeManager 以及 每个计算程序的 MRAppMaster（详情见 YARN 架构）。一个完整的 MapReduce 计算程序在分布式运行时有三类进程：</p>
<ul>
<li><p>MRAppMaster: 既Driver程序，负责整个程序的过程调度及状态协调。</p>
</li>
<li><p>MapTask：负责 Map 阶段的整个数据处理流程。</p>
</li>
<li><p>ReduceTask：负责 Reduce 阶段的整个数据处理流程。</p>
</li>
</ul>
<p><img src="https://lc-gluttony.s3.amazonaws.com/xavRfmuNYmLc/XpINY08xfTey0a1Lv28rPWRirp5QwtzV/MapReduce-Flow.png" 
     alt = "MapReduce-Flow" ondragstart="return false;" onContextMenu="return false;" style="zoom:85%"/></p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>适用于海量大数据离线计算分析（OLAP），对于计算耗时敏感性不高（非毫秒级或者秒级返回结果），以及需要使用代码实现的复杂计算逻辑。</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol>
<li><p><strong>支持海量大数据</strong> (PB 级以上) 离线计算；可从 HDFS中 读取多种格式的数据文件。</p>
</li>
<li><p><strong>编程简单</strong>：通常实现 <code>org.apache.hadoop.mapred.Mapper</code> 与 <code>org.apache.hadoop.mapred.Reducer</code> 等接口以及编写<code>“Driver”</code> 即可完成分布式并行运算。</p>
</li>
<li><p><strong>较强的扩展性</strong>：当计算资源不足的时，可通过简单的机器扩容以达到水平扩展，计算程序或系统本身无需代码更变。</p>
</li>
<li><p><strong>较高的容错性</strong>：当一个或多个计算任务失败时，系统会将其分配到其他机器节点上进行重试，从而保证任务不至于一次性失败。</p>
</li>
</ol>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol>
<li>时效性较低：不支持实时计算，无法达到像普通 RDBMS 一样的毫秒级查询分析。</li>
<li>无法进行流式计算：由于流式计算的数据源为动态的，但 MapReduce 框架所针对的均为静态数据，所以无法进行流式计算。</li>
<li>不能较好处理数据流转：每个 MapReduce 任务必须将数据写入文件系统（HDFS）中， 从而在处理有前后依赖性（DAG/有向无环图）的计算任务时，需频繁将中间数据写入磁盘，造成大量 IO 消耗。</li>
</ol>
<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p>以下罗列出MapReduce框架中的主要核心组件，并阐明功能与使用方法。随着Hadoop MapReduce版本的更新，需不断对照源码进行理解。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.mr.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="Writable"><a href="#Writable" class="headerlink" title="Writable"></a>Writable</h3><p>由于 Java 自身的序列化机制 (java.io.Serializable) 较重，对象在被序列化时会携带额外信息。因此为了减少存储占用，以及网络传输带宽，Hadoop 设计了自己的序列化机制。该序列化机制 (Writable) 更紧凑，高效，且兼容性更强。需要序列化的自定义类对象可实现<code>org.apache.hadoop.io.Writable</code>或<code>org.apache.hadoop.io.WritableComparable</code>接口。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Writable</span> </span>&#123;</span><br><span class="line">  <span class="comment">/** Serialize the fields of this object to &lt;code&gt;out&lt;/code&gt; */</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Deserialize the fields of this object from &lt;code&gt;in&lt;/code&gt;  */</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>: 序列化与反序列化时，Class-Field顺序必须保持一致！</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">WritableComparable</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">Writable</span>, <span class="title">Comparable</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(T object)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>: 如果自定义类对象需作为 MR 中的 <strong>KEY</strong>，则必须实现 <code>java.lang.Comparable</code>接口。因为在 Shuffle 过程中会针对 <strong>KEY</strong> 进行排序！</p>
<p>常用数据类型对比</p>
<table>
<thead>
<tr>
<th><strong>Java 类型</strong></th>
<th><strong>Hadoop Writable 类型</strong></th>
</tr>
</thead>
<tbody><tr>
<td>boolean</td>
<td>BooleanWritable</td>
</tr>
<tr>
<td>byte</td>
<td>ByteWritable</td>
</tr>
<tr>
<td>int</td>
<td>IntWritable</td>
</tr>
<tr>
<td>float</td>
<td>FloatWritable</td>
</tr>
<tr>
<td>long</td>
<td>LongWritable</td>
</tr>
<tr>
<td>double</td>
<td>DoubleWritable</td>
</tr>
<tr>
<td>String</td>
<td>Text</td>
</tr>
<tr>
<td>Map</td>
<td>MapWritable</td>
</tr>
<tr>
<td>Array</td>
<td>ArrayWritable</td>
</tr>
<tr>
<td><em>null</em></td>
<td><em>NullWritable</em></td>
</tr>
</tbody></table>
<h3 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h3><p>InputFormat 负责对原始数据源进行读取操作。通常会先针对数据文件切片，并通过对应的 <strong>RecordReader</strong> 进行读取。默认的抽象类为<code>org.apache.hadoop.mapred.FileInputFormat</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">InputFormat</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">/** Logically split the set of input files for the job.  */</span></span><br><span class="line">  InputSplit[] getSplits(JobConf job, <span class="keyword">int</span> numSplits) <span class="keyword">throws</span> IOException;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Get the RecordReader */</span></span><br><span class="line">  <span class="function">RecordReader&lt;K, V&gt; <span class="title">getRecordReader</span><span class="params">(InputSplit split,  JobConf job, Reporter reporter)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote style="border-left: 6px solid Lime; background: #GhostWhite;">
在默认情况下切片大小等于 HDFS 中存储的文件块 (Block) 大小 (128或256MB)。也可以通过 mapreduce.input.fileinputformat.split.minsize 
设置切片最小字节数，以及 mapreduce.input.fileinputformat.split.maxsize 设置切片最大字节数。
</blockquote>

<p><strong>RecordReader</strong> 具体可参考此[文档](<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.1/api/org/apache/hadoop/mapreduce/RecordReader.html">RecordReader (Apache Hadoop Main 3.2.1 API)</a>)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** RecordReader reads &lt;key, value&gt; pairs from an InputSplit. */</span></span><br><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">RecordReader</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">Closeable</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">  <span class="comment">/** Reads the next key/value pair from the input for processing   */</span>      </span><br><span class="line">  <span class="function"><span class="keyword">boolean</span> <span class="title">next</span><span class="params">(K key, V value)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/**  Create an object of the appropriate type to be used as a key */</span></span><br><span class="line">  <span class="function">K <span class="title">createKey</span><span class="params">()</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/** Create an object of the appropriate type to be used as a value */</span></span><br><span class="line">  <span class="function">V <span class="title">createValue</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Returns the current position in the input */</span></span><br><span class="line">  <span class="function"><span class="keyword">long</span> <span class="title">getPos</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Close the RecordReader */</span></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Return how much of the input has been processed by [0.0, 1.0] */</span></span><br><span class="line">  <span class="function"><span class="keyword">float</span> <span class="title">getProgress</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h3><p>Mapper负责MapReduce - MapTask的核心逻辑。具体可参考此<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.1/api/org/apache/hadoop/mapreduce/Mapper.html">文档</a>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Mapper</span>&lt;<span class="title">KEYIN</span>, <span class="title">VALUEIN</span>, <span class="title">KEYOUT</span>, <span class="title">VALUEOUT</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Context</span> <span class="keyword">implements</span> <span class="title">MapContext</span>&lt;<span class="title">KEYIN</span>,<span class="title">VALUEIN</span>,<span class="title">KEYOUT</span>,<span class="title">VALUEOUT</span>&gt; </span>&#123;&#125;</span><br><span class="line">  <span class="comment">/** Task Begins */</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123; <span class="comment">/* Custom Logic If Necessary  */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(KEYIN key, VALUEIN value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">/* Custom Logic  */</span></span><br><span class="line">    context.write((KEYOUT) _key, (VALUEOUT) _value);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/** Task Ends */</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123; <span class="comment">/* Custom Logic If Necessary  */</span>&#125;</span><br><span class="line">  <span class="comment">/** Advanced Functions */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123; <span class="comment">/* ... */</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h3><p>Reducer负责MapReduce - ReduceTask的核心逻辑。具体可参考此<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.1/api/org/apache/hadoop/mapreduce/Reducer.html">文档</a>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Checkpointable</span></span><br><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Reducer</span>&lt;<span class="title">KEYIN</span>,<span class="title">VALUEIN</span>,<span class="title">KEYOUT</span>,<span class="title">VALUEOUT</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Context</span> <span class="keyword">implements</span> <span class="title">ReduceContext</span>&lt;<span class="title">KEYIN</span>,<span class="title">VALUEIN</span>,<span class="title">KEYOUT</span>,<span class="title">VALUEOUT</span>&gt; </span>&#123;&#125;</span><br><span class="line">  <span class="comment">/**  Task Begins */</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;<span class="comment">/* Custom Logic If Necessary  */</span>&#125;</span><br><span class="line">  <span class="comment">/**  Key with Values */</span></span><br><span class="line">  <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(KEYIN key, Iterable&lt;VALUEIN&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">/* Custom Logic  1 */</span></span><br><span class="line">    <span class="keyword">for</span> (VALUEIN value: values) &#123;</span><br><span class="line">      <span class="comment">/* Custom Logic 2 */</span></span><br><span class="line">      context.write((KEYOUT) key, (VALUEOUT) value);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/** Task Ends */</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">cleanup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123; <span class="comment">/* Custom Logic If Necessary  */</span>&#125;</span><br><span class="line">  <span class="comment">/** Advanced Usage  */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123; <span class="comment">/* ... */</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Partitioner"><a href="#Partitioner" class="headerlink" title="Partitioner"></a>Partitioner</h3><p>当需要将数据按照不同类别 / 属性分开存储时，则需要使用 <strong>Partitioner</strong>。 默认分区是根据 <strong>KEY</strong> 的 hashCode 和 reduceTasks 个数取余得到 (<em>org.apache.hadoop.mapreduce.lib.partition.HashPartitioner</em>)。若按照自定义条件进行分区，则需要继承<code>org.apache.hadoop.mapreduce.Partitioner</code>类并重写 getPartition(…) 方法。由此MR框架可根据自定义逻辑将结果 Key-Value 进行分区。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Partitioner</span>&lt;<span class="title">KEY</span>, <span class="title">VALUE</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">/** </span></span><br><span class="line"><span class="comment">   * Get the partition number for a given key &amp; value &amp; total number of partitions.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> the partition number for the key.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(KEY key, VALUE value, <span class="keyword">int</span> numPartitions)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在Job中设置自定义分区逻辑后，还<strong>要根据 Partitioner 的条件</strong>在Job里<strong>设置相应的 Reduce Task 数量</strong>。</p>
<p><strong>注意：</strong></p>
<ul>
<li><p>当 <strong>ReduceTask</strong> 数量 <strong>大于</strong> getPartition(…) 返回的最大数值，则系统会多生成（ReduceTask数 - getPartition 最大值）空的输出文件，任务成功。</p>
</li>
<li><p>当 <strong>ReduceTask</strong> 数量 <strong>大于</strong> 1 <strong>且 小于</strong> getPartition(…) 返回的最大数值，则有一部分分区数据无法存储，系统抛出 Exception，任务失败。</p>
</li>
<li><p>当 <strong>ReduceTask</strong> 数量 <strong>等于</strong> 1，则无论MapTask端输出多少个分区文件，最终都交给一个 ReduceTask，结果存储在一个文件中 (part-r-00000)。任务成功，但耗时可能较高。</p>
</li>
</ul>
<h3 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h3><p>Combiner 是 MapReduce 程序之外的一种组件，其父类依旧是<code>org.apache.hadoop.mapred.Reducer</code>。Combiner在每个MapTask所在节点运行，而Reducer则负责处理全局Mapper的输出结果。Combiner的作用是为了对每个MapTask的输出进行<strong>局部</strong>汇总，以减少网络开销。但<strong>并非所有计算场景都可以使用Combiner</strong>。</p>
<h3 id="OutputFormat"><a href="#OutputFormat" class="headerlink" title="OutputFormat"></a>OutputFormat</h3><p>OutputFormat 负责 MapReduce 计算结果的最终输出所需的 RecordWriter 创建/获取，在ReduceTask之后执行。所有MR输出均需要实现该类 (<code>org.apache.hadoop.mapred.OutputFormat</code>)。系统默认的输出格式为 <strong>TextOutputFormat</strong>，继承于<code>org.apache.hadoop.mapred.FileOutputFormat</code>。</p>
<p><strong>OutputFormat</strong> 具体可参考此<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.1/api/org/apache/hadoop/mapreduce/OutputFormat.html">文档</a>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">OutputFormat</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">/** Return  RecordWriter to write the output for the job */</span>      </span><br><span class="line">  <span class="function">RecordWriter&lt;K, V&gt; <span class="title">getRecordWriter</span><span class="params">(FileSystem ignored, JobConf job, String name, Progressable progress)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">checkOutputSpecs</span><span class="params">(FileSystem ignored, JobConf job)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>RecordWriter</strong> 具体可参考此<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.1/api/org/apache/hadoop/mapreduce/RecordWriter.html">文档</a>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">RecordWriter</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">/**  Writes a key/value pair  */</span>      </span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">write</span><span class="params">(K key, V value)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Close the RecordWriter to future operations */</span> </span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">close</span><span class="params">(Reporter reporter)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h3><p>MapReduce Driver 程序包含整个MR过程 <strong>Main</strong> 方法入口，负责创建并配置计算任务 (<code>org.apache.hadoop.mapreduce.Job</code>)。通过 <em>Job.getInstance(config)</em> 可创建任务。其中基础参数由<code>org.apache.hadoop.conf.Configuration</code>或<code>org.apache.hadoop.mapred.JobConf</code>设置。</p>
<p>Job类中常用方法如下，具体可参考此<a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r3.2.1/api/org/apache/hadoop/mapreduce/Job.html">文档</a>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Public</span></span><br><span class="line"><span class="meta">@Evolving</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Job</span> <span class="keyword">extends</span> <span class="title">JobContextImpl</span> <span class="keyword">implements</span> <span class="title">JobContext</span>, <span class="title">AutoCloseable</span> </span>&#123;</span><br><span class="line">  <span class="comment">// …… Fields &amp; Methods ……</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setJobName</span><span class="params">(String name)</span> <span class="keyword">throws</span> IllegalStateException </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUser</span><span class="params">(String user)</span> </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setJarByClass</span><span class="params">(Class&lt;?&gt; cls)</span> </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addCacheFile</span><span class="params">(URI uri)</span>  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCacheFiles</span><span class="params">(URI[] files)</span>  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMapperClass</span><span class="params">(Class&lt;? extends Mapper&gt; cls)</span> <span class="keyword">throws</span> IllegalStateException </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setReducerClass</span><span class="params">(Class&lt;? extends Reducer&gt; cls)</span> <span class="keyword">throws</span> IllegalStateException </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">   </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPartitionerClass</span><span class="params">(Class&lt;? extends Partitioner&gt; cls)</span> <span class="keyword">throws</span> IllegalStateException  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCombinerClass</span><span class="params">(Class&lt;? extends Reducer&gt; cls)</span> <span class="keyword">throws</span> IllegalStateException  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMapOutputKeyClass</span><span class="params">(Class&lt;?&gt; theClass)</span> <span class="keyword">throws</span> IllegalStateException  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMapOutputValueClass</span><span class="params">(Class&lt;?&gt; theClass)</span> <span class="keyword">throws</span> IllegalStateException  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOutputKeyClass</span><span class="params">(Class&lt;?&gt; theClass)</span> <span class="keyword">throws</span> IllegalStateException </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOutputValueClass</span><span class="params">(Class&lt;?&gt; theClass)</span> <span class="keyword">throws</span> IllegalStateException </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNumReduceTasks</span><span class="params">(<span class="keyword">int</span> tasks)</span> <span class="keyword">throws</span> IllegalStateException </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">submit</span><span class="params">()</span>  <span class="keyword">throws</span> Exception  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">waitForCompletion</span><span class="params">(<span class="keyword">boolean</span> verbose)</span> <span class="keyword">throws</span> Exception  </span>&#123; <span class="comment">/* …… */</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p><img src="https://lc-gluttony.s3.amazonaws.com/xavRfmuNYmLc/VH2jsDU8TFwtC2EWwVRvHIMkdFFf0TPc/MR-Basic-Diagram.png" 
     alt="MR-Basic-Diagram" ondragstart="return false;" onContextMenu="return false;" style="zoom:70%" /></p>
<h3 id="MapTask"><a href="#MapTask" class="headerlink" title="MapTask"></a>MapTask</h3><p><strong><em>MapTask主要运行阶段</em></strong></p>
<ul>
<li>数据读取：由 <strong>InputFormat</strong> 获取相应的 <strong>RecordReader</strong> 以读取数据源文件。之后通过 InputSplit 解析出相对的 <strong>Key - Value</strong>。</li>
<li>Map阶段：基于输入的 <strong>Key - Value</strong> 执行用户自定义的 <strong>Mapper</strong> 逻辑，随后输出一组新的 <strong>Key - Value</strong>。</li>
<li>数据采集：Mapper 输出的数据在通过OutputCollector.collect(K key, V value) 方法后被写入<strong>环形缓冲区</strong> (kvbuffer, 当前默认100MB) 进行<strong>分区</strong>和<strong>快速排序</strong>。</li>
<li>数据溢写：当存储量达到环形缓冲区大小 80% 后进行反向溢写 (Spill) ，MapReduce 将数据写到本地磁盘上，形成一个临时文件。</li>
<li>文件合并：将多个溢写的临时小文件合并成一个数据文件，同时生成索引文件 以等待 ReduceTask 读取。</li>
</ul>
<p><strong><em>MapTask并行度</em></strong></p>
<p>一个 MapReduce 任务 Map 阶段的并行度与客户端提交的数据切片个数相关。系统会为每一个切片分配一个 MapTask 以并行处理。在默认情况下切片大小 等于 HDFS 中的文件块 (Block) 大小。也可以通过 <code>mapreduce.input.fileinputformat.split.minsize</code> 设置切片最小字节数，<code>mapreduce.input.fileinputformat.split.maxsize</code> 设置切片最大字节数。</p>
<p><code>org.apache.hadoop.mapred.FileInputFormat</code> 类中的 computeSplitSize 方法包含具体取值逻辑。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@InterfaceAudience</span>.Public</span><br><span class="line"><span class="meta">@InterfaceStability</span>.Stable</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">FileInputFormat</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">InputFormat</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> InputSplit[] getSplits(JobConf job, <span class="keyword">int</span> numSplits) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="comment">// Prepare Logic</span></span><br><span class="line">    <span class="keyword">long</span> goalSize = totalSize / (numSplits == <span class="number">0</span> ? <span class="number">1</span> : numSplits);</span><br><span class="line">    <span class="keyword">long</span> minSize = Math.max(job.getLong(FileInputFormat.SPLIT_MINSIZE, <span class="number">1</span>), minSplitSize);</span><br><span class="line">    <span class="keyword">long</span> blockSize = file.getBlockSize();</span><br><span class="line">    <span class="keyword">long</span> splitSize = computeSplitSize(goalSize, minSize, blockSize);</span><br><span class="line">    <span class="comment">// Return Logic</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 计算方法</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">computeSplitSize</span><span class="params">(<span class="keyword">long</span> goalSize, <span class="keyword">long</span> minSize, <span class="keyword">long</span> blockSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Math.max(minSize, Math.min(goalSize, blockSize));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="ReduceTask"><a href="#ReduceTask" class="headerlink" title="ReduceTask"></a>ReduceTask</h3><p><strong><em>ReduceTask主要运行阶段</em></strong></p>
<ul>
<li><p>数据拉取：每个 ReduceTask 主动从HDFS中读取相应分区的数据，并复制到本地磁盘中（如在阈值之内则直接写入内存）。</p>
</li>
<li><p>归并排序：将同一分区，源于不同 MapTask 的数据文件进行<strong>归并排序</strong>。</p>
</li>
<li><p>Reduce阶段：执行用户自定义 Reducer 逻辑。</p>
</li>
<li><p>结果输出：由 OutputFormat 获取相应的 RecorderWriter 以按照一定格式将结果输出。</p>
</li>
</ul>
<p><strong><em>ReduceTask并行度</em></strong></p>
<p>ReduceTask 并行度与数据分区密切相关，可通过 Job.setNumReduceTasks(Int number) 或者 <em>mapreduce.job.reduces</em> 设置。默认分区计算逻辑由 HashPartitioner 承载。也可以通过自定义分区器来实现不同的分区逻辑。</p>
<blockquote style="border-left: 6px solid Lime; background: #GhostWhite;">
若一个MapReduce任务 ReduceTask 为数量0，则表示没有Reduce阶段，结果文件数与MapTask个数一致。
ReduceTask 默认个数为1，如果数据分布不均匀，则会在ReduceTask产生数据倾斜！
</blockquote>


<h3 id="完整流程"><a href="#完整流程" class="headerlink" title="完整流程"></a>完整流程</h3><p><img src="https://lc-gluttony.s3.amazonaws.com/xavRfmuNYmLc/fD834ihjjk0boAoUosnKC9zbn7cpEHyH/MapReduce-Diagram.png" 
     alt="MapReduce-Diagram" ondragstart="return false;" onContextMenu="return false;" style="zoom:80%" /></p>
<p>输入分片 -&gt; Map阶段 -&gt; Combiner阶段 (可选) -&gt; Shuffle阶段 -&gt; Reduce阶段 -&gt; 结果输出</p>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="什么是Shuffle"><a href="#什么是Shuffle" class="headerlink" title="什么是Shuffle"></a>什么是Shuffle</h3><p>在 Mapper.map(…) 方法之后，Reducer.reduce(…) 方法之前的处理过程，通常叫做Shuffle。其中Shuffle的缓冲区大小会影响到 计算的执行效率，缓冲区越大，磁盘 IO 的次数越少，执行速度就越快。</p>
<h3 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h3><p>Reduce Join 用于关联2个数据源数据，实现 SQL 中 <strong>JOIN</strong> 的功能。</p>
<p>在 Map 阶段，读取来自不同数据源文件输入的 Key - Value 对，并打标签以区分。 随后使用关联字段作为 Key，其余部分和标志作为Value，最后输出。<br>在 Reduce 阶段，将每一个分组中来源自不同数据源的 Value（根据标签）分开，并按一定逻辑进行合并输出。</p>
<h3 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h3><p>当两个需要关联的数据源中，存在一个数据量级较小的时候，可将该数据源全部加载至内存，按关键字建立索引。数据量级较大的则作为 Map 部分输入，在Maper.map() 方法中针对每一个键值对，使其按关联字段与事先加载到内存的小数据集进行连接。最后将结果按 Key 输出，即可得到关联后的数据。</p>
<p>Map Join 需使用Hadoop中的 <strong>DistributedCache</strong> 把数量级小的数据源分发到各个计算节点；在每个 Mapper 的 setup 阶段加载到内存中进行缓存。Map Join 过程中无ReduceTask。</p>
<blockquote style="border-left: 6px solid Lime; background: #GhostWhite;">
    Map Join 方法常用于解决普通Join过程中 数据倾斜 的问题。
</blockquote>


<hr>
<blockquote>
<p>当前直接使用 MapReduce 框架编程以实现大数据计算的方案逐渐被淘汰，可选择 Apache Hive + UDF，或 Apache Spark 等更先进的框架/计算引擎代替！</p>
<p>作者后续也将着重介绍相关技术与实战经验。</p>
</blockquote>
<img alt="Medivh's Diary" style="zoom: 70%" src="https://lc-gluttony.s3.amazonaws.com/xavRfmuNYmLc/gRiY2OQoPCSE2fYvdPAHhhx6aAMJAVYM/%E9%BA%A6%E8%BF%AA%E6%96%87%E6%97%A5%E8%AE%B0%E5%85%AC%E4%BC%97%E5%8F%B7.gif" />



        </div>


        
            <section class="post-copyright">
                
                
                
                    <p class="copyright-item">
                        <span><i>License:</i></span>&nbsp;
                        <span><a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                
                    <span>
                        <i>Visitors:</i>&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                
                
            </section>
        
        <br/>
        
        

        <section class="post-tags">
            <div>
                <span>Tag:</span>
                <span class="tag">
                    
                    
                        <a href="/tags/Big-Data/">#Big Data</a>
                    
                        <a href="/tags/Hadoop/">#Hadoop</a>
                    
                        <a href="/tags/MapReduce/">#MapReduce</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">Back</a>
                <span>· </span>
                <a href="/">Home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2022/10/Markdown-Skill/">写最棒的笔记，用最牛的工具 -- Markdown</a>
            
            
            <a class="next" rel="next" href="/2021/11/Hadoop-HDFS/">Hadoop HDFS (分布式文件系统)</a>
            
        </section>

        
        
        <div id="lv-container" style="text-align: center" data-id="city"
             data-uid="MTAyMC81MTcyNC8yODIwNQ==">
            <script type="text/javascript">
                (function(d, s) {
                    var j, e = d.getElementsByTagName(s)[0];
                    if (typeof LivereTower === 'function') {
                        return;
                    }
                    j = d.createElement(s);
                    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                    j.async = true;
                    e.parentNode.insertBefore(j, e);
                })(document, 'script');
            </script>
        </div>
        
    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
		<span>© <a href="/">Jason Ge Wu</a>&nbsp;&nbsp;|&nbsp;&nbsp;Powered by
        	<a href="https://hexo.io" target="_blank">Hexo</a>
        </span>
    </div>
</footer>

    </div>
</body>
</html>
